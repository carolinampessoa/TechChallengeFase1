{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUTeIAgor0O7TsofRZEHtf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolinampessoa/TechChallengeFase1/blob/main/TechChallengeFase1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando bibliotecas\n",
        "\n"
      ],
      "metadata": {
        "id": "V31k57x3RjZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas para leitura e carregamento de dataset do Kaggle\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "# Bibliotecas para visualização de dados\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Bibliotecas para ajuste de dados\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# Bibliotecas para treinamento de modelos\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Bibliotecas para validação de modelos\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "-i_ymd6yRszD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Passo 1: Exploração de dados\n",
        "\n",
        "Baixando a base de dados e explorando suas características\n"
      ],
      "metadata": {
        "id": "TeUOb53jSHoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"mirichoi0218/insurance\");\n",
        "df = pd.read_csv(os.path.join(path, \"insurance.csv\"));"
      ],
      "metadata": {
        "id": "PyM7F3CVSZPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "csWZQwEeRz4a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fmViGb6zR3X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4dK7WpSqR6By"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sRpngr6iR2qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVfgKcqqQ1q_",
        "outputId": "9d0ec8f7-afd1-4662-86d2-edd41d1e137f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deseja fazer a análise exploratória dos dados? (s/n)\n",
            "n\n",
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
            "\n",
            "Resultados dos Modelos (conjunto de treino):\n",
            "              Modelo    R²     RMSE      MAE  MAPE (%)\n",
            "0  Linear Regression  0.51  8391.12  4270.77     27.02\n",
            "1      Decision Tree  1.00   554.21    29.57      0.50\n",
            "2      Random Forest  0.96  2396.26   987.11      7.62\n",
            "3                KNN  0.80  5357.56  2813.33     21.14\n",
            "4            XGBoost  0.88  4181.86  1917.21     14.49\n",
            "\n",
            "Resultados dos Modelos (conjunto de treino):\n",
            "              Modelo    R²     RMSE      MAE  MAPE (%)\n",
            "0  Linear Regression  0.58  8050.05  4011.62     28.86\n",
            "1      Decision Tree  0.75  6171.27  2978.59     36.48\n",
            "2      Random Forest  0.87  4413.00  2249.35     22.44\n",
            "3                KNN  0.74  6326.59  3453.60     28.24\n",
            "4            XGBoost  0.88  4310.42  1958.12     15.56\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Bibliotecas\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Bibliotecas para ajuste de dados\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# Bibliotecas para treinamento de modelos\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Bibliotecas para validação de modelos\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "#===============================================================================================================\n",
        "\n",
        "# Passo 1: Exploração de dados\n",
        "\n",
        "# ======== 1.1: Carregue a base de dados e explore suas características\n",
        "\n",
        "# Baixando o dataset da Kaggle e lendo o arquido CSV, transformando-o em um DataFrame\n",
        "path = kagglehub.dataset_download(\"mirichoi0218/insurance\");\n",
        "df = pd.read_csv(os.path.join(path, \"insurance.csv\"));\n",
        "\n",
        "print(\"Deseja fazer a análise exploratória dos dados? (s/n)\");\n",
        "resposta = input().strip().lower();\n",
        "\n",
        "if resposta == 's':\n",
        "    # Exibindo as primeiras linhas do DataFrame\n",
        "    print(df.head());\n",
        "\n",
        "    # Colunas: age, sex (contractor gender), BMI (Body mass index - ratio of height to weight, ideally 18.5 to 24.9),\n",
        "    #  children (number of children covered by health insurance/number of dependents), smoker, region (residential area in the US),\n",
        "    #  charges (target - individual medical costs billed by health insurance )\n",
        "\n",
        "    #Verificando dimensões e características do DataFrame\n",
        "    print(\"Formato do dataset (linhas, colunas):\", df.shape); # Dimensões: 1338 x 7\n",
        "    print(\"\\nInformações do DataFrame:\");\n",
        "    print(df.info());  # Tipos de dados: categóricas(sex, smoker, region), inteiro (age, children) e float (BMI, charges).\n",
        "\n",
        "    # ======== 1.2: Analise estatísticas descritivas e visualize distribuições relevantes.\n",
        "\n",
        "    #Analisando estatísticas descritivas do DataFrame\n",
        "    print(\"\\nEstatísticas descritivas:\")\n",
        "    print(df.describe()) # Valores de média, minimo, máximo e etc são coerentes.\n",
        "\n",
        "    #Configurar estilo dos gráficos\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    #1. Distribuição das variáveis  numéricas\n",
        "    df.hist(bins=50,figsize=(20,15));\n",
        "    # Maioria com custos médicos entre R$1.000 e R$20.000.\n",
        "    # Distribuição de custos altamente assimétrica à direita, com alguns pacientes incorrendo em custos significativamente altos. Isso pode indicar a presença de casos especiais, como pacientes com doenças crônicas ou tratamentos caros.\n",
        "    # Idade: distribuição relativamente uniforme entre 18 e 64 anos. Variação moderada. Média próxima da mediana (simetria);\n",
        "    # BMI: Dados variando entre 15.96 (muito abaixo do peso) e 53,13 (obesidade severa). 75% A distribuição é levemente assimétrica à direita, indicando a presença de pacientes com IMC significativamente alto.\n",
        "    # Filhos: pouca variabilidade dos dados, provavelmente tem pouco impacto nos custos médicos.\n",
        "\n",
        "    # 2. Relação entre idade e custos\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.scatterplot(x='age', y='charges', hue='smoker', data=df)\n",
        "    plt.title(\"Idade vs. Custos Médicos (diferenciado por fumantes)\")\n",
        "    plt.show()\n",
        "    # Para não fumantes, os custos aumentam gradualmente com a idade.\n",
        "    # Para fumantes, os custos são significativamente mais altos, mesmo em idades mais jovens.\n",
        "    # A variável smoker tem um impacto substancial nos custos médicos, mais do que a idade isoladamente.\n",
        "\n",
        "    # 3. Boxplot dos custos por região\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(x='region', y='charges', data=df)\n",
        "    plt.title(\"Custos Médicos por Região\")\n",
        "    plt.show()\n",
        "    # As medianas dos custos são relativamente semelhantes entre as regiões.\n",
        "    # A região Sudeste apresenta uma maior variabilidade nos custos, com alguns outliers significativos.\n",
        "    # Embora a região tenha algum impacto, ele é menos pronunciado do que o status de fumante.\n",
        "\n",
        "    # 4. Boxplot dos custos por status de fumante\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(x='smoker', y='charges', data=df)\n",
        "    plt.title(\"Custos Médicos por Status de Fumante\")\n",
        "    plt.show()\n",
        "    # Fumantes têm custos médicos significativamente mais altos, com uma mediana muito superior à dos não fumantes.\n",
        "    # A variabilidade dos custos entre fumantes também é maior, indicando casos extremos.\n",
        "    # O status de fumante é um forte preditor dos custos médicos.\n",
        "\n",
        "    # 5. Correlação entre variáveis numéricas\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
        "    plt.title(\"Mapa de Calor das Correlações\")\n",
        "    plt.show()\n",
        "    # Charges tem correlação positiva com age e BMI, sendo mais forte com age.\n",
        "    # A correlação entre BMI e charges é moderada, sugerindo que o BMI também influencia os custos.\n",
        "    #  variável children tem pouca correlação com charges, indicando impacto limitado.\n",
        "\n",
        "    # Conclusões da Análise Exploratória:\n",
        "    # O status de fumante é o fator mais influente nos custos médicos.\n",
        "    # Idade e IMC também contribuem para o aumento dos custos, mas em menor escala.s\n",
        "    # A presença de outliers sugere a necessidade de técnicas robustas ou transformações nos dados para modelagem eficaz.\n",
        "\n",
        "#===============================================================================================================\n",
        "\n",
        "# Passo 2: Pré-processamento de dados\n",
        "\n",
        "# ======== 1.1: Realize a limpeza dos dados, tratando valores ausentes (se necessário)\n",
        "\n",
        "    print(df.info());  # Não há valores nulos na base da dados do Kaggle.\n",
        "\n",
        "# ======== 2.1: Converta variáveis categóricas em formatos adequados para modelagem\n",
        "\n",
        "num_attribs = list(df.select_dtypes(include=['number']).columns.drop(\"charges\"));  # Selecionando colunas numéricas\n",
        "cat_attribs = list(df.select_dtypes(include=['object']).columns);  # Selecionando colunas categóricas\n",
        "if resposta == 's':\n",
        "    print(\"Atributos numéricos:\", num_attribs);\n",
        "    print(\"Atributos categóricos:\", cat_attribs);\n",
        "\n",
        "# Criando pipeline para converter variáveis categóricas em variáveis dummy usando one-hot encoding (sem ordem intrínsica entre os valores)\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", StandardScaler(), num_attribs),# tratando as variáveis numéricas (normalização)\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs), # tratando as variáveis categóricas\n",
        "    ]);\n",
        "\n",
        "#===============================================================================================================\n",
        "\n",
        "# Passo 3: Modelagem\n",
        "\n",
        "# ======== 3.1: Crie um modelo preditivo de regressão utilizando uma técnica à sua escolha\n",
        "\n",
        "#Regressão Linear (simples, interpretável).\n",
        "\n",
        "model_lr = LinearRegression();\n",
        "\n",
        "#Árvore de Decisão (captura não linearidades).\n",
        "\n",
        "model_dtr = DecisionTreeRegressor(random_state=42);\n",
        "\n",
        "#Regressão com Random Forest (mais robusta).\n",
        "\n",
        "model_rfr = RandomForestRegressor(random_state=42);\n",
        "\n",
        "# Regressão com KNN (bom para dados não lineares, mas pode ser lento em grandes datasets).\n",
        "\n",
        "model_knn = KNeighborsRegressor(n_neighbors=5);\n",
        "\n",
        "#Regressão com XGBoost com otimização de parâmetros (eficiente para grandes datasets, lida bem com não linearidades e interações entre variáveis).\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0,],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "model_xgb = GridSearchCV(\n",
        "    estimator=XGBRegressor(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_absolute_error',  # Ou 'neg_mean_squared_error'\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    n_jobs=-1  # Usa todos os núcleos da CPU\n",
        ")\n",
        "\n",
        "# ======== 3.2: Divida o conjunto de dados em conjuntos de treinamento e teste\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42);\n",
        "\n",
        "def preProcessamento(dataset):\n",
        "    x = dataset.drop(\"charges\", axis=1)  # Apagando a target para a base de treino (nosso X)\n",
        "    y = dataset.pop(\"charges\")  # Separando a coluna target (charges) do DataFrame de treino (nosso Y)\n",
        "    y_log = np.log(y)  # Transformando a variável target charges em log para lidar com a assimetria dos dados\n",
        "    x_prepared = full_pipeline.fit_transform(x)  # Aplicando o pipeline de pré-processamento\n",
        "    x_prepared = pd.DataFrame(x_prepared, columns=num_attribs + list(full_pipeline.named_transformers_['cat'].get_feature_names_out(cat_attribs)))  # Convertendo para DataFrame\n",
        "    return x_prepared, y, y_log\n",
        "\n",
        "x_train, y_train, y_train_log = preProcessamento(df_train)  # Pré-processando os dados de treino\n",
        "x_test, y_test, y_test_log = preProcessamento(df_test)  # Pré-processando os dados de teste\n",
        "\n",
        "#===============================================================================================================\n",
        "\n",
        "# Passo 4: Treinamento e avaliação do modelo\n",
        "\n",
        "# ======== 4.1: Treine o modelo com o conjunto de treinamento\n",
        "# Treinando os modelos com a variável target transformada em log para lidar com a assimetria dos dados\n",
        "model_lr.fit(x_train, y_train_log);\n",
        "model_dtr.fit(x_train, y_train_log);\n",
        "model_rfr.fit(x_train, y_train_log);\n",
        "model_knn.fit(x_train, y_train_log);\n",
        "model_xgb.fit(x_train, y_train_log);\n",
        "\n",
        "# Lista de modelos e seus nomes\n",
        "modelos = {\n",
        "    \"Linear Regression\": model_lr,\n",
        "    \"Decision Tree\": model_dtr,\n",
        "    \"Random Forest\": model_rfr,\n",
        "    \"KNN\": model_knn,\n",
        "    \"XGBoost\": model_xgb\n",
        "}\n",
        "\n",
        "def avaliar_modelos(modelos, x, y_real, usar_log=False):\n",
        "    \"\"\"\n",
        "    Avalia múltiplos modelos e retorna um DataFrame com métricas de desempenho.\n",
        "\n",
        "    Parâmetros:\n",
        "    - modelos: dicionário {nome: modelo}\n",
        "    - x: conjunto de entrada (features)\n",
        "    - y_real: valores reais (target)\n",
        "    - usar_log: True se os modelos foram treinados com log(y) e precisam de np.exp() nas previsões\n",
        "\n",
        "    Retorna:\n",
        "    - DataFrame com R², RMSE, MAE e MAPE\n",
        "    \"\"\"\n",
        "    resultados = {\n",
        "        \"Modelo\": [],\n",
        "        \"R²\": [],\n",
        "        \"RMSE\": [],\n",
        "        \"MAE\": [],\n",
        "        \"MAPE (%)\": []\n",
        "    }\n",
        "\n",
        "    for nome, modelo in modelos.items():\n",
        "        y_pred = modelo.predict(x)\n",
        "        if usar_log:\n",
        "            y_pred = np.exp(y_pred)\n",
        "\n",
        "        errors = np.abs(y_real - y_pred)\n",
        "        relative_errors = errors / np.abs(y_real)\n",
        "        mape = np.mean(relative_errors) * 100\n",
        "\n",
        "        resultados[\"Modelo\"].append(nome)\n",
        "        resultados[\"R²\"].append(r2_score(y_real, y_pred))\n",
        "        resultados[\"RMSE\"].append(np.sqrt(mean_squared_error(y_real, y_pred)))\n",
        "        resultados[\"MAE\"].append(mean_absolute_error(y_real, y_pred))\n",
        "        resultados[\"MAPE (%)\"].append(mape)\n",
        "\n",
        "    return pd.DataFrame(resultados).round(2)\n",
        "\n",
        "\n",
        "df_resultados_treino = avaliar_modelos(modelos, x_train, y_train, usar_log=True)\n",
        "print(\"\\nResultados dos Modelos (conjunto de treino):\")\n",
        "print(df_resultados_treino)\n",
        "\n",
        "\n",
        "#===============================================================================================================\n",
        "\n",
        "# Passo 5: Validação estatística\n",
        "\n",
        "# ======== 5.1: Utilize métricas estatísticas para validar a eficácia do modelo (p-value, intervalos de confiança)\n",
        "\n",
        "# Avaliação de todos os modelos usando a base de teste (generalização)\n",
        "\n",
        "df_resultados_teste = avaliar_modelos(modelos, x_test, y_test, usar_log=True)\n",
        "print(\"\\nResultados dos Modelos (conjunto de treino):\")\n",
        "print(df_resultados_teste)\n",
        "\n",
        "# Modelo escolhido: XGBoost (melhor desempenho geral)\n",
        "# Avaliando métricas estatísticas para validar a eficácia do modelo\n",
        "\n",
        "# Interpretação:\n",
        "# p-values < 0.05 → coeficiente é estatisticamente significativo.\n",
        "# Intervalos de confiança estreitos → maior confiabilidade nas estimativas.\n",
        "# R² ajustado alto → bom ajuste considerando o número de variáveis.\n",
        "\n",
        "# ======== 5.2: Apresente resultados visuais, como gráficos de previsões vs. valores reais\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.scatter(df_train_labels, y_train_pred, alpha=0.5)\n",
        "# plt.xlabel(\"Valores reais\")\n",
        "# plt.ylabel(\"Previsões\")\n",
        "# plt.title(\"Previsões vs. Valores Reais (conjunto de treino)\")\n",
        "# plt.plot([0, max(df_test_labels)], [0, max(df_test_labels)], color='red', linestyle='--')  # linha ideal\n",
        "# plt.show()\n",
        "\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.scatter(df_test_labels, y_test_pred, alpha=0.5)\n",
        "# plt.xlabel(\"Valores reais\")\n",
        "# plt.ylabel(\"Previsões\")\n",
        "# plt.title(\"Previsões vs. Valores Reais (conjunto de Teste)\")\n",
        "# plt.plot([0, max(df_test_labels)], [0, max(df_test_labels)], color='red', linestyle='--')  # linha ideal\n",
        "# plt.show()\n",
        "\n",
        "# ======== 5.3: Elabore um relatório que inclua uma análise dos resultados, insights obtidos e validação estatística\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*texto em itálico*# Nova seção"
      ],
      "metadata": {
        "id": "FzBEQuILQ608"
      }
    }
  ]
}