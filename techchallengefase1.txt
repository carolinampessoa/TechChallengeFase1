# -*- coding: utf-8 -*-
"""TechChallengeFase1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/carolinampessoa/TechChallengeFase1/blob/main/TechChallengeFase1.ipynb

## **Passo 0: Importação de bibliotecas**
"""

# Bibliotecas para leitura e carregamento de dataset do Kaggle
import kagglehub
import pandas as pd
import os
# Bibliotecas para visualização de dados
import seaborn as sns
import matplotlib.pyplot as plt
# Bibliotecas para ajuste de dados
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
# Bibliotecas para treinamento de modelos
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV
# Bibliotecas para validação de modelos
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np
import statsmodels.api as sm
import shap

"""## **Passo 1: Exploração de dados**

Baixando a base de dados e explorando suas características
"""

path = kagglehub.dataset_download("mirichoi0218/insurance");
df = pd.read_csv(os.path.join(path, "insurance.csv"));

# Exibindo as primeiras linhas e formato do DataFrame
print(df.head());
print("Formato do dataset (linhas, colunas):", df.shape);

"""Base de dados de composta por 1338 registros e 7 colunas, sendo 6 variáveis de entrada (idade, genero, IMC, número de filhos, fumante e região) e uma váriavel de saída (custos - variável target)."""

# Características do DataFrame
print("\nInformações do DataFrame:");
print(df.info());  # Tipos de dados: categóricas(sex, smoker, region), inteiro (age, children) e float (BMI, charges).

"""Tipos de dados presentes no dataset: categóricas (sex, smoker, region), inteiros (age, children) e float (BMI, charges). Não existem valores nulos na base de dados."""

print("\nEstatísticas descritivas:")
print(df.describe())
print("\nDistribuição das variáveis  numéricas:")
num_attribs = list(df.select_dtypes(include=['number']))

for i, var in enumerate(num_attribs):
    plt.subplot(2, 2, i + 1) # Cria uma grade de 2x2 subplots
    sns.histplot(df[var], kde=True, bins=30, color='skyblue')
    plt.title(f'Distribuição de {var.capitalize()}')
    plt.xlabel(var.capitalize())
    plt.ylabel('Frequência')

plt.tight_layout() # Ajusta o layout para evitar sobreposição
plt.show()

"""Insights das métricas e análises de distribuição:

* Custos: grande maioria das pessoas com custos médicos entre 1k e 20k. Distribuição de custos altamente assimétrica à direita, com alguns pacientes incorrendo em custos significativamente altos (mais de R$ 50k). Isso pode indicar a presença de casos especiais, como pacientes com doenças crônicas ou tratamentos caros. Pode ser necessário um tratamento específico para lidar com esses outliers;
* Idade: distribuição relativamente uniforme entre 18 e 64 anos. Média próxima da mediana, indicando certa simetria. A amostra representa bem diferentes faixas etárias sem um viés muito forte para jovens ou idosos (embora seja limitada a 64 anos).
* BMI: Dados variando entre 15.96 (muito abaixo do peso) e 53,13 (obesidade severa). A distribuição é levemente assimétrica à direita, indicando a presença de pacientes com IMC significativamente alto.
* Filhos: distribuição bastante assimétrica à direita, ou seja, a grande maioria das pessoas avaliadas tem poucos filhos.

Avaliando a correlação individual das variáveis de entrada numéricas com a variável target:
"""

fig, axes = plt.subplots(1, 3, figsize=(18, 5))  # 1 linha, 3 colunas

# 1. Scatterplot: Idade vs. Custos Médicos
sns.scatterplot(x='age', y='charges', hue='smoker', data=df, ax=axes[0])
axes[0].set_title("Idade vs. Custos Médicos (smoker)")

# 2. Scatterplot: Filhos vs. Custos Médicos
sns.scatterplot(x='children', y='charges', data=df, ax=axes[1])
axes[1].set_title("Filhos vs. Custos Médicos")

# 3. Scatterplot: BMI vs. Custos Médicos
sns.scatterplot(x='bmi', y='charges', hue='smoker', data=df, ax=axes[2])
axes[2].set_title("IMC vs. Custos Médicos (smoker)")

plt.tight_layout()
plt.show()

fig, axes = plt.subplots(1, 3, figsize=(18, 5))  # 1 linha, 3 colunas

# 1. Boxplot: Custos Médicos por Genero
sns.boxplot(x='sex', y='charges', data=df, ax=axes[0])
axes[0].set_title("Custos Médicos por Gênero")

# 2. Boxplot: Custos Médicos por Região
sns.boxplot(x='region', y='charges', data=df, ax=axes[1])
axes[1].set_title("Custos Médicos por Região")

# 3. Boxplot: Custos Médicos por Status de Fumante
sns.boxplot(x='smoker', y='charges', data=df, ax=axes[2])
axes[2].set_title("Custos Médicos por Status de Fumante")

plt.tight_layout()
plt.show()

"""Principais insights da análise de dados:

* O status de fumante (smoker) é, de longe, a variável com o impacto mais claro e significativo nos custos médics;
* A idade é outro preditor robusto, com custos aumentando consistentemente à medida que a pessoa envelhece;
* O IMC tem uma relação positiva com os custos, mas com uma variabilidade considerável. Sua influência pode ser mais aparente quando combinada com outros fatores (como fumar);
* O número de filhos, por si só, não parece ser um fator determinante para os custos do plano de saúde;
* A região onde o paciente reside também tem um impacto discernível, com o Southeast mostrando custos consistentemente mais altos. Isso pode indicar diferenças socioeconômicas, de estilo de vida ou de acesso à saúde;
* O gênero, isoladamente, parece ter um impacto marginal nos custos, com uma pequena diferença na mediana, mas sem grande poder explicativo;
* Todos os box plots reforçam a natureza assimétrica dos charges (com a cauda longa para cima, indicando muitos outliers de alto custo);
* A visualização Idade vs. Custos (smoker) e IMC vs. Custos (smoker) demonstra a importância de explorarmos as interações entre as variáveis;
* A presença de outliers sugere a necessidade de técnicas robustas ou transformações nos dados para modelagem eficaz.

## **Passo 2: Pré-processamento de dados**

Limpeza de dados: conforme avaliado anteriormente, a base de dados não possui dados nulos. Caso contrário, poderia ser usada técnicas como substituição pela média ou mediana e criado um pipeline específico para isso com a classe *Imputer* do scikit-learn.

Normalizando as variáveis numéricas para compensar diferenças de escala e convertendo as variáveis categóricas (gênero, status de fumante e região) em formatos adequados para modelagem:
"""

num_attribs = list(df.select_dtypes(include=['number']).columns.drop("charges"));  # Selecionando colunas numéricas
cat_attribs = list(df.select_dtypes(include=['object']).columns);  # Selecionando colunas categóricas

full_pipeline = ColumnTransformer([
        ("num", StandardScaler(), num_attribs),# tratando as variáveis numéricas (normalização)
        ("cat", OneHotEncoder(), cat_attribs), # tratando as variáveis categóricas
    ]);

"""## **Passo 3: Modelagem**

Criando diferentes modelos para posterior treinamento e comparação da capacidade preditiva:
"""

# Regressão Linear (simples, interpretável).
model_lr = LinearRegression();

# Árvore de Decisão
model_dtr = DecisionTreeRegressor();

# Regressão com Random Forest
model_rfr = RandomForestRegressor();

# Regressão com KNN
model_knn = KNeighborsRegressor();

# Regressão com XGBoost com otimização de parâmetros (lida bem com não linearidades e interações entre variáveis).
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0,],
    'colsample_bytree': [0.8, 1.0]
}

model_xgb = GridSearchCV(
    estimator=XGBRegressor(random_state=42),
    param_grid=param_grid,
    scoring='neg_mean_absolute_error',  # Ou 'neg_mean_squared_error'
    cv=3,
    verbose=1,
    n_jobs=-1  # Usa todos os núcleos da CPU
)

"""Dividindo o conjunto de dados em subconjuntos de treinamento e teste e aplicando a pipeline de pré-processamento em cada um:"""

df_train, df_test = train_test_split(df, test_size=0.2, random_state=42);

def preProcessamento(dataset):
    x = dataset.drop("charges", axis=1)  # Apagando a target para a base de treino (X)
    y = dataset.pop("charges")  # Separando a coluna target (charges) do DataFrame de treino (Y)
    y_log = np.log(y)  # Transformando a variável target charges em log para lidar com a assimetria dos dados
    x_prepared = full_pipeline.fit_transform(x)  # Aplicando o pipeline de pré-processamento
    x_prepared = pd.DataFrame(x_prepared, columns=num_attribs + list(full_pipeline.named_transformers_['cat'].get_feature_names_out(cat_attribs)))  # Convertendo para DataFrame
    return x_prepared, y, y_log

x_train, y_train, y_train_log = preProcessamento(df_train)  # Pré-processando os dados de treino
x_test, y_test, y_test_log = preProcessamento(df_test)  # Pré-processando os dados de teste

"""A variável target (custos) foi transformada por uma função logarítimica a fim de lidar com a assimemtria dos dados e outliers. Foi cogitada a possibilidade de remoção dos outliers, porém isso limitaria o modelo a uma faixa específica de predição, limitando-se a valores típicos. Assim, optou-se pela transformação da variável buscando-se um modelo mais generalista."""

# Lista de modelos e seus nomes
modelos = {
    "Linear Regression": model_lr,
    "Decision Tree": model_dtr,
    "Random Forest": model_rfr,
    "KNN": model_knn,
    "XGBoost": model_xgb
}

"""## **Passo 4: Treinamento e avaliação do modelo**

Criando função para treinamento e avaliação dos modelos, para posterior comparação:
"""

def avaliar_modelos(modelos, x, y_real, usar_log=False):
    """
    Avalia múltiplos modelos e retorna um DataFrame com métricas de desempenho.

    Parâmetros:
    - modelos: dicionário {nome: modelo}
    - x: conjunto de entrada (features)
    - y_real: valores reais (target)
    - usar_log: True se os modelos foram treinados com log(y) e precisam de np.exp() nas previsões

    Retorna:
    - DataFrame com R², RMSE, MAE e MAPE
    """
    resultados = {
        "Modelo": [],
        "R²": [],
        "RMSE": [],
        "MAE": [],
        "MAPE (%)": []
    }

    for nome, modelo in modelos.items():
        y_pred = modelo.predict(x)
        if usar_log:
            y_pred = np.exp(y_pred)

        errors = np.abs(y_real - y_pred)
        relative_errors = errors / np.abs(y_real)
        mape = np.mean(relative_errors) * 100

        resultados["Modelo"].append(nome)
        resultados["R²"].append(r2_score(y_real, y_pred))
        resultados["RMSE"].append(np.sqrt(mean_squared_error(y_real, y_pred)))
        resultados["MAE"].append(mean_absolute_error(y_real, y_pred))
        resultados["MAPE (%)"].append(mape)

    return pd.DataFrame(resultados).round(2)

# Treinando os modelos com a variável target original, sem transformação logaritmica
for nome, modelo  in modelos.items():
    modelo.fit(x_train, y_train);

"""## **Passo 5: Validação estatística**

Avaliando a capacidade de generalização dos modelos utilizando o conjunto de teste:
"""

df_resultados_teste = avaliar_modelos(modelos, x_test, y_test, usar_log=False)
print("\nResultados dos Modelos:\n")
print(df_resultados_teste)

# Treinando os modelos com a variável target transformada em log para lidar com a assimetria dos dados
for nome, modelo  in modelos.items():
    modelo.fit(x_train, y_train_log);
    if nome == "XGBoost":
      modelos[nome] = modelo.best_estimator_


df_resultados_teste = avaliar_modelos(modelos, x_test, y_test, usar_log=True)
print("\nResultados dos Modelos:\n")
print(df_resultados_teste)

"""A transformação logaritmica da variável target reduziu o MAE e MAPE de todos os modelos, porém aumentou o RMSE. Isso sugere que o modelo está, em geral, melhor em termos de precisão relativa e na média dos erros absolutos, especialmente para a maioria dos pontos de dados (os valores menores de custos).

### Análise SHAP
"""

# Calcular os valores SHAP
shap.initjs()
# Now pass the best_estimator_ to SHAP explainer
explainer = shap.Explainer(modelos["XGBoost"], x_test)
shap_values = explainer(x_test)

shap.summary_plot(shap_values, x_test, plot_type="bar")

"""### Gráficos de previsões vs valores reais"""

# Obter previsões de todos os modelos no conjunto de teste
y_preds = {}
for nome, modelo in modelos.items():
    y_pred = modelo.predict(x_test)
    y_pred = np.exp(y_pred)  # Inverte a transformação log
    y_preds[nome] = y_pred

# Criar os gráficos em uma grade 2x3
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

# Plotar os gráficos
for i, (nome, y_pred) in enumerate(y_preds.items()):
    ax = axes[i]
    sns.scatterplot(x=y_test, y=y_pred, ax=ax, alpha=0.6)
    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    ax.set_title(f'{nome}\nR² = {r2_score(y_test, y_pred):.2f}')
    ax.set_xlabel('Valor Real')
    ax.set_ylabel('Previsão')
    ax.grid(True)

# Remover subplot extra (posição 6 não usada)
if len(y_preds) < len(axes):
    for j in range(len(y_preds), len(axes)):
        fig.delaxes(axes[j])

plt.tight_layout()
plt.suptitle("Comparação: Previsões vs Valores Reais (Test Set)\n", fontsize=16, y=1.02)
plt.show()

"""## **Conclusões Finais**

Após testar cinco algoritmos de regressão — **Regressão Linear**, **Árvore de Decisão**, **Random Forest**, **KNN** e **XGBoost** — observamos que modelos mais complexos, como **Random Forest** e **XGBoost**, apresentaram melhor desempenho geral quando comparados com modelos mais simples como a Regressão Linear.

Os **principais destaques** foram:

* O status de fumante mostrou-se um dos preditores mais relevantes, conforme demonstrado pelos gráficos de correlação e análise SHAP;
* Variáveis como idade, IMC e filhos também contribuíram para as variações nos custos, mas com menor intensidade;
* A transformação logarítmica da variável "charges" (custos) foi fundamental para lidar com a assimetria da distribuição e melhorar a performance preditiva, ajudando o modelo a aprender padrões que são mais proporcionais à magnitude dos custos. O aumento de RMSE, no entanto, indica que a transformação logarítmica (e a subsequente "back-transformation") está levando a alguns erros absolutos muito grandes para um pequeno número de observações de alto valor (os outliers de custo). Esses erros extremos, quando elevados ao quadrado, distorcem o RMSE para cima;
* Os modelos RandomForest e XGBoost, ambos baseados em árvores de decisão, foram os que apresentaram melhor desempenho na predição dos custos a partir das variáveis de entrada, com um R² acima de 0.87 e um MAPE menor que 22%.
* Embora o XGBoost tenha apresentado estatísticas de erro menores, seu treinamento exigiu mais esforço computacional. Isso indica que, para treinamento de bases de dados maiores, o RandomForest pode apresentar um melhor custo-benefício;

Apesar dos **bons resultados** obtidos com modelos como o XGBoost, é importante **destacar algumas limitações**:

1. O conjunto de dados é relativamente pequeno (~1300 registros) e pode não capturar completamente a diversidade da população. Isso limita a capacidade do modelo de generalizar para novos contextos;

2. Informações como histórico médico, condições crônicas, uso de medicamentos ou frequência de visitas médicas não estão presentes no dataset. Esses fatores poderiam melhorar significativamente a acurácia das previsões;

O modelo treinado pode ser **útil em diversos cenários**, como:

* **Precificação de seguros**: estimar o custo esperado de um novo cliente com base em seus dados pessoais e comportamentais;
* **Programas de saúde corporativa**: identificar perfis com maior risco de custo para focar intervenções preventivas;
* **Educação em saúde**: demonstrar o impacto de fatores de estilo de vida (como fumar) sobre os custos médicos futuros.

Contudo, para uso em produção real, seria necessário revalidar o modelo com bases de dados maiores e mais recentes e garantir o cumprimento de normas éticas e legais (LGPD, HIPAA, etc.) no uso dos dados sensíveis.

Por fim, este projeto demonstrou a importância da análise prévia dos dados para criação do pipeline de processamento, escolha dos modelos e entendimento das limitações do modelo;  da escolha de bons preditores (lineares e não lineares), capazes de capturar a variabilidade dos dados; da aplicação de tratamentos e transformações adequadas nas variáveis de entrada e/ou saída (como o uso do log) e da validação do desempenho de cada método através de métricas estatísticas e representações visuais.
"""